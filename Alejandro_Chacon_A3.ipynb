{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alechacon99/INST767-SP2023/blob/main/Alejandro_Chacon_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3\n",
        "\n",
        "In the assignment, you are asked to calculate the PMI of words in the Shakespeare collection.\n",
        "\n",
        "PMI is defined as the follows:\n",
        "\n",
        "$$PMI(x,y) = \\log\\frac{p(x,y)}{p(x)p(y)}$$\n",
        "\n",
        "The larger the magnitude of PMI for $x$ and $y$ is, the more information you know about the probability of seeing $y$ having just seen $x$ (and vice-versa, since PMI is symmetrical). If seeing $x$ gives you no information about seeing $y$, then $x$ and $y$ are independent and the PMI is zero. You may want to check out this classic paper [Word association norms, mutual information, and lexicography](https://aclanthology.org/J90-1003.pdf) if you'd like a more detailed discussion on the use of PMI in NLP.\n",
        "\n",
        "For this assignment, $p(x)$ is the probability of seeing word $x$, and it should be calculated by deviding the word count of $x$ by the total word count. $p(x,y)$ is the probability of seeing word $x$ and $y$ cooccurring in the same line, it should be calculated by deviding the cooccurrence of the two words by the total word count. We provided an example PMI calculation function for you.\n",
        "\n",
        "As discussed in the lecture session, please write two separate implementations, one using the broadcasting mechanism in Spark, and the other using join. Please save your result in `/content/pmi_broadcast` (for broadcasting implementation) and `/content/pmi_join` (for using join). \n",
        "\n",
        "**Please pay attention to the following specifications:**\n",
        "\n",
        "1. In addition to PMI, it's also important to know how many times the pair actually co-occurs, so you'll include this information in the output. Each each line should contain four elements, seperated by a tab char (\"\\t\")\n",
        "\n",
        "  - word1, \n",
        "  - word2, \n",
        "  - cooccurrence of the two words, \n",
        "  - PMI of the two words. \n",
        "2. To reduce the number of spurious pairs, please filter out pairs that occur few times. Please use a threshold of 10, that is, we are only interested in pairs of words that co-occur in ten or more lines.\n",
        "3. To submit, download your notebook as a ipynb file and uploaded it to ELMS."
      ],
      "metadata": {
        "id": "nL35ZMuH7AuX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh773ypvGOIx"
      },
      "source": [
        "# Installing Spark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ffvqmCG53k"
      },
      "source": [
        "Downloading Apache Spark from a repository, unzipping, and installing it. This step may take up to 10 mins to run. So please be patient.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8b-sb7eGG73"
      },
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!readlink -f /usr/bin/java | sed \"s:bin/java::\""
      ],
      "metadata": {
        "id": "aJSyoMH8iIun",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b3050a-3ec3-41aa-f270-5790ff8fefaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/jvm/java-11-openjdk-amd64/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDMtxpKsHiBc"
      },
      "source": [
        "Setting up environment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbXriBSxHGU3"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "exuHwmhhiRg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Shakespeare Dataset\n",
        "\n",
        "Here we load the Shakespeare dataset as a RDD for you.\n",
        "\n",
        "We have also provided some \"helper\" codes."
      ],
      "metadata": {
        "id": "6ditnz3pttct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.gutenberg.org/cache/epub/100/pg100.txt\n",
        "!mv pg100.txt /content/shakespeare.txt"
      ],
      "metadata": {
        "id": "Pnk6_PkIiX3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8HVgcS6JpH_"
      },
      "source": [
        "shakespeare = sc.textFile('/content/shakespeare.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "PAT = re.compile(\"(^[^a-z]+|[^a-z]+$)\")\n",
        "\n",
        "def tokenize(line):\n",
        "    #tokenize the string, remove unnecessary characters\n",
        "    tokens = [re.sub(PAT, \"\", t.lower()) for t in line.split()]\n",
        "    #returning non-empty strings as tokenization result\n",
        "    return list(filter(lambda x:len(x)>0, tokens))"
      ],
      "metadata": {
        "id": "5mA1XWgXitMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feel free to use the following sentences to debug.\n",
        "sentences = ['a fox jumps over the lazy dog',\n",
        "             'fox jumps over the lazy dog',\n",
        "             'jumps over the lazy dog',\n",
        "             '',\n",
        "             '',\n",
        "             'i really really like spark',\n",
        "             'really really']"
      ],
      "metadata": {
        "id": "Nnz2qNnQi8Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This prepares the word count that you are familiar with.\n",
        "word_freq = shakespeare.flatMap(tokenize) \\\n",
        "          .map(lambda word: (word, 1)) \\\n",
        "          .reduceByKey(lambda a, b: a + b)"
      ],
      "metadata": {
        "id": "itCzBzp0nd5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pairs(tokens):\n",
        "  for i in range(len(tokens)):\n",
        "    for j in range(i+1, len(tokens)):\n",
        "      # we are not interested the coocurrence of the same word.\n",
        "      if tokens[i] == tokens[j]:\n",
        "        continue\n",
        "      yield (tokens[i], tokens[j])\n",
        "      yield (tokens[j], tokens[i])"
      ],
      "metadata": {
        "id": "Cb71X9o3yO1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cells prepares the cooccurrence count, which we have demonstrated in class.\n",
        "pairs = shakespeare.map(tokenize).flatMap(lambda x:get_pairs(x))\n",
        "pairs_count = pairs.map(lambda x:(x,1)).reduceByKey(lambda a, b: a + b)"
      ],
      "metadata": {
        "id": "PIPNypABxR_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell provides a sample implementation of PMI calculation, feel free to use this.\n",
        "# Note that word_count_total is the count of all tokens. Since this is a integer, there is no need to broadcast it.\n",
        "import math\n",
        "\n",
        "def calc_pmi(word1_count, word2_count, word12_cooccur, word_count_total):\n",
        "  fx = word1_count / word_count_total\n",
        "  fy = word2_count / word_count_total\n",
        "  fxy = word12_cooccur / word_count_total\n",
        "  return math.log(fxy / (fx * fy), 10)"
      ],
      "metadata": {
        "id": "kUb4wvSH5RQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate PMI using Broadcast [4 points]\n",
        "Let's start by calculating PMI using the broadcasting mechanism of Spark. We have write a few lines of code to get you started"
      ],
      "metadata": {
        "id": "CNcmguwk391r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_freq_counter = Counter()"
      ],
      "metadata": {
        "id": "5E9Jo_uBrKYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in word_freq.collect():\n",
        "  word_freq_counter[word] = count"
      ],
      "metadata": {
        "id": "xRVCTOoLrKPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_wc = sum(word_freq_counter.values())"
      ],
      "metadata": {
        "id": "DBauygnpthq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq_counter_bc = sc.broadcast(word_freq_counter) # bc = broadcast"
      ],
      "metadata": {
        "id": "WX5S8B00rdkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please write your codes below. Feel free to add more cells as you wish."
      ],
      "metadata": {
        "id": "0wL3Kn-76FTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pairs counr's tuple looks like ((A, B), n)\n",
        "\n",
        "find n_A, n_B in word_freq_counter_bc.value by looking up x[0][0], x[0][1]"
      ],
      "metadata": {
        "id": "ZWbZZWhdxdzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_pmi = pairs_count.map(lambda x : (x[0], x[1], word_freq_counter_bc.value(x[0][0]), word_freq_counter_bc.value(x[0][1]))) \\\n",
        "  .map(lambda y: f'{y[0][0]}\\t{y[0][1]}\\t{y[1][0]}\\t{calc_pmi(y[1][2], y[1][3], y[1][2], total_wc)}') \\\n",
        "  .filter(lambda z: z[3] >= 10)\n",
        "\n",
        "## y looks like (A, B), n, n_A, n_B using y....\n",
        "## for desired format consider \n"
      ],
      "metadata": {
        "id": "la-AeBqX6EwG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_pmi.collect()"
      ],
      "metadata": {
        "id": "BP7aEWTW6EtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7lLfzWqW6Eh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate PMI using join [4 points]\n",
        "\n",
        "Please write your codes below. Feel free to add more cells as you wish.\n",
        "\n"
      ],
      "metadata": {
        "id": "5eMYkxS7x-cV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pairs_count (A, B), n \n",
        "word_freq (A, n_A)\n",
        "\n",
        "((A, B), n) -> (A, (B, n)) -> ((A, B), n, n_)\n",
        "((A< B), n) -> x[0] is (A, B), x[1] is n,\n",
        "A <- x[0][0]\n",
        "B <- x[0][1]\n",
        "n <- x[1]\n",
        "(a, (B,n)) is (x[0][0], (x[0][1], x[1]))\n",
        "\n",
        "(A, (B, n)), (A, n_A) ----join----> (A, ((B, n), n_A)\n",
        "\n",
        "map again to get ((A, B), n, n_A) or maybe map to (B, (A, n, n_A))?\n",
        "\n",
        "(B, (A, n, n_A)), (B, n_B) ----join----> (B, ((A, n, n_A), n_B)\n",
        "\n",
        "final map to ((A, B), n, n_A, n_B)"
      ],
      "metadata": {
        "id": "2LKK8nkD1r0g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQx6UFhZ7HW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gCKgDoEG2g-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answer a few questions with your result [2 points]\n",
        "\n",
        "1. How many distinct PMI pairs did you extract?\n",
        "\n",
        "2. What's the pair (x, y) (or pairs if there are ties) with the highest PMI? Use Similarly, what's the pair with the lowest (negative) PMI? Do you find the results make sense? Write a sentence or two to explain why or why not.\n",
        "\n",
        "You can compute the answer to the two questions however you wish and you're not required to use Spark."
      ],
      "metadata": {
        "id": "0j6R_i_l8gcY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AhcLaSD6-Ag6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3U53D1U-BP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cIUBBIsd-BAv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}